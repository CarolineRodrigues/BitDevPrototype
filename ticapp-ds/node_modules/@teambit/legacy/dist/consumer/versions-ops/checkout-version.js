"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");

require("core-js/modules/es.array.flat.js");

require("core-js/modules/es.array.iterator.js");

require("core-js/modules/es.array.unscopables.flat.js");

require("core-js/modules/es.promise.js");

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.applyModifiedVersion = applyModifiedVersion;
exports.applyVersion = applyVersion;
exports.default = checkoutVersion;
exports.deleteFilesIfNeeded = deleteFilesIfNeeded;
exports.markFilesToBeRemovedIfNeeded = markFilesToBeRemovedIfNeeded;

function _defineProperty2() {
  const data = _interopRequireDefault(require("@babel/runtime/helpers/defineProperty"));

  _defineProperty2 = function () {
    return data;
  };

  return data;
}

function _lodash() {
  const data = require("lodash");

  _lodash = function () {
    return data;
  };

  return data;
}

function _pMapSeries() {
  const data = _interopRequireDefault(require("p-map-series"));

  _pMapSeries = function () {
    return data;
  };

  return data;
}

function path() {
  const data = _interopRequireWildcard(require("path"));

  path = function () {
    return data;
  };

  return data;
}

function _bitId() {
  const data = require("../../bit-id");

  _bitId = function () {
    return data;
  };

  return data;
}

function _constants() {
  const data = require("../../constants");

  _constants = function () {
    return data;
  };

  return data;
}

function _generalError() {
  const data = _interopRequireDefault(require("../../error/general-error"));

  _generalError = function () {
    return data;
  };

  return data;
}

function _repositories() {
  const data = require("../../scope/repositories");

  _repositories = function () {
    return data;
  };

  return data;
}

function _path2() {
  const data = require("../../utils/path");

  _path2 = function () {
    return data;
  };

  return data;
}

function _manyComponentsWriter() {
  const data = _interopRequireDefault(require("../component-ops/many-components-writer"));

  _manyComponentsWriter = function () {
    return data;
  };

  return data;
}

function _dataToPersist() {
  const data = _interopRequireDefault(require("../component/sources/data-to-persist"));

  _dataToPersist = function () {
    return data;
  };

  return data;
}

function _removePath() {
  const data = _interopRequireDefault(require("../component/sources/remove-path"));

  _removePath = function () {
    return data;
  };

  return data;
}

function _mergeVersion() {
  const data = require("./merge-version");

  _mergeVersion = function () {
    return data;
  };

  return data;
}

function _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== "function") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function (nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }

function _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { (0, _defineProperty2().default)(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }

async function checkoutVersion(consumer, checkoutProps) {
  const {
    version,
    ids,
    promptMergeOptions
  } = checkoutProps; // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!

  const {
    components
  } = await consumer.loadComponents(ids);
  await consumer.scope.import(_bitId().BitIds.fromArray(ids || []));
  const allComponentsStatus = await getAllComponentsStatus();
  const componentWithConflict = allComponentsStatus.find(component => component.mergeResults && component.mergeResults.hasConflicts);

  if (componentWithConflict) {
    if (!promptMergeOptions && !checkoutProps.mergeStrategy) {
      throw new (_generalError().default)(`automatic merge has failed for component ${componentWithConflict.id.toStringWithoutVersion()}.\nplease use "--manual" to manually merge changes or use "--theirs / --ours" to choose one of the conflicted versions`);
    }

    if (!checkoutProps.mergeStrategy) checkoutProps.mergeStrategy = await (0, _mergeVersion().getMergeStrategyInteractive)();
  }

  const failedComponents = allComponentsStatus.filter(componentStatus => componentStatus.failureMessage).map(componentStatus => ({
    id: componentStatus.id,
    failureMessage: componentStatus.failureMessage,
    unchangedLegitimately: componentStatus.unchangedLegitimately
  }));
  const succeededComponents = allComponentsStatus.filter(componentStatus => !componentStatus.failureMessage); // do not use Promise.all for applyVersion. otherwise, it'll write all components in parallel,
  // which can be an issue when some components are also dependencies of others

  const componentsResults = await (0, _pMapSeries().default)(succeededComponents, ({
    id,
    componentFromFS,
    mergeResults
  }) => {
    return applyVersion(consumer, id, componentFromFS, mergeResults, checkoutProps);
  });
  markFilesToBeRemovedIfNeeded(succeededComponents, componentsResults);
  const componentsWithDependencies = componentsResults.map(c => c.component).filter(c => c);

  if (componentsWithDependencies.length) {
    const manyComponentsWriter = new (_manyComponentsWriter().default)({
      consumer,
      componentsWithDependencies,
      installNpmPackages: !checkoutProps.skipNpmInstall,
      override: true,
      verbose: checkoutProps.verbose,
      writeDists: !checkoutProps.ignoreDist,
      writeConfig: checkoutProps.writeConfig,
      writePackageJson: !checkoutProps.ignorePackageJson,
      resetConfig: checkoutProps.reset
    });
    await manyComponentsWriter.writeAll();
    await deleteFilesIfNeeded(componentsResults, consumer);
  }

  const appliedVersionComponents = componentsResults.map(c => c.applyVersionResult);
  return {
    components: appliedVersionComponents,
    version,
    failedComponents
  };

  async function getAllComponentsStatus() {
    const tmp = new (_repositories().Tmp)(consumer.scope);

    try {
      const componentsStatusP = components.map(component => getComponentStatus(consumer, component, checkoutProps));
      const componentsStatus = await Promise.all(componentsStatusP);
      await tmp.clear();
      return componentsStatus;
    } catch (err) {
      await tmp.clear();
      throw err;
    }
  }
}

async function getComponentStatus(consumer, component, checkoutProps) {
  const {
    version,
    latestVersion,
    reset
  } = checkoutProps;
  const repo = consumer.scope.objects;
  const componentModel = await consumer.scope.getModelComponentIfExist(component.id);
  const componentStatus = {
    id: component.id
  };

  const returnFailure = (msg, unchangedLegitimately = false) => {
    componentStatus.failureMessage = msg;
    componentStatus.unchangedLegitimately = unchangedLegitimately;
    return componentStatus;
  };

  if (!componentModel) {
    return returnFailure(`component ${component.id.toString()} doesn't have any version yet`);
  }

  const unmerged = repo.unmergedComponents.getEntry(component.name);

  if (!reset && unmerged && unmerged.resolved === false) {
    return returnFailure(`component ${component.id.toStringWithoutVersion()} has conflicts that need to be resolved first, please use bit merge --resolve/--abort`);
  }

  const getNewVersion = async () => {
    // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
    if (reset) return component.id.version; // @ts-ignore if !reset the version is defined

    return latestVersion ? componentModel.latestIncludeRemote(repo) : version;
  };

  const newVersion = await getNewVersion();

  if (version && !latestVersion) {
    const hasVersion = await componentModel.hasVersion(version, repo);
    if (!hasVersion) return returnFailure(`component ${component.id.toStringWithoutVersion()} doesn't have version ${version}`);
  }

  const existingBitMapId = consumer.bitMap.getBitId(component.id, {
    ignoreVersion: true
  });
  const currentlyUsedVersion = existingBitMapId.version;

  if (!currentlyUsedVersion) {
    return returnFailure(`component ${component.id.toStringWithoutVersion()} is new`);
  }

  if (version && currentlyUsedVersion === version) {
    // it won't be relevant for 'reset' as it doesn't have a version
    return returnFailure(`component ${component.id.toStringWithoutVersion()} is already at version ${version}`);
  }

  if (latestVersion && currentlyUsedVersion === newVersion) {
    return returnFailure(`component ${component.id.toStringWithoutVersion()} is already at the latest version, which is ${newVersion}`, true);
  }

  const currentVersionObject = await componentModel.loadVersion(currentlyUsedVersion, repo);
  const isModified = await consumer.isComponentModified(currentVersionObject, component);

  if (!isModified && reset) {
    return returnFailure(`component ${component.id.toStringWithoutVersion()} is not modified`);
  } // this is tricky. imagine the user is 0.0.2+modification and wants to checkout to 0.0.1.
  // the base is 0.0.1, as it's the common version for 0.0.1 and 0.0.2. however, if we let git merge-file use the 0.0.1
  // as the base, then, it'll get the changes done since 0.0.1 to 0.0.1, which is nothing, and put them on top of
  // 0.0.2+modification. in other words, it won't make any change.
  // this scenario of checking out while there are modified files, is forbidden in Git. here, we want to simulate a similar
  // experience of "git stash", then "git checkout", then "git stash pop". practically, we want the changes done on 0.0.2
  // to be added to 0.0.1
  // if there is no modification, it doesn't go the threeWayMerge anyway, so it doesn't matter what the base is.


  const baseVersion = currentlyUsedVersion;
  const baseComponent = await componentModel.loadVersion(baseVersion, repo);
  let mergeResults; // if the component is not modified, no need to try merge the files, they will be written later on according to the
  // checked out version. same thing when no version is specified, it'll be reset to the model-version later.

  if (version && isModified) {
    const otherComponent = await componentModel.loadVersion(newVersion, repo);
    mergeResults = await (0, _mergeVersion().threeWayMerge)({
      consumer,
      otherComponent,
      otherLabel: newVersion,
      currentComponent: component,
      currentLabel: `${currentlyUsedVersion} modified`,
      baseComponent
    });
  }

  const versionRef = componentModel.getRef(newVersion); // @ts-ignore

  const componentVersion = await consumer.scope.getObject(versionRef.hash);
  const newId = component.id.changeVersion(newVersion); // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!

  return {
    componentFromFS: component,
    componentFromModel: componentVersion,
    id: newId,
    mergeResults
  };
}
/**
 * 1) when the files are modified with conflicts and the strategy is "ours", leave the FS as is
 * and update only bitmap id version. (not the componentMap object).
 *
 * 2) when the files are modified with conflicts and the strategy is "theirs", write the component
 * according to id.version.
 *
 * 3) when files are modified with no conflict or files are modified with conflicts and the
 * strategy is manual, load the component according to id.version and update component.files.
 * applyModifiedVersion() docs explains what files are updated/added.
 *
 * 4) when --reset flag is used, write the component according to the bitmap version
 *
 * Side note:
 * Deleted file => if files are in used version but not in the modified one, no need to delete it. (similar to git).
 * Added file => if files are not in used version but in the modified one, they'll be under mergeResults.addFiles
 */


async function applyVersion(consumer, id, componentFromFS, // it can be null only when isLanes is true
mergeResults, checkoutProps) {
  if (!checkoutProps.isLane && !componentFromFS) throw new Error(`applyVersion expect to get componentFromFS for ${id.toString()}`);
  const {
    mergeStrategy
  } = checkoutProps;
  let filesStatus = {};

  if (mergeResults && mergeResults.hasConflicts && mergeStrategy === _mergeVersion().MergeOptions.ours) {
    // even when isLane is true, the mergeResults is possible only when the component is on the filesystem
    // otherwise it's impossible to have conflicts
    if (!componentFromFS) throw new Error(`applyVersion expect to get componentFromFS for ${id.toString()}`);
    componentFromFS.files.forEach(file => {
      filesStatus[(0, _path2().pathNormalizeToLinux)(file.relative)] = _mergeVersion().FileStatus.unchanged;
    });
    consumer.bitMap.updateComponentId(id);
    return {
      applyVersionResult: {
        id,
        filesStatus
      }
    };
  }

  const componentWithDependencies = await consumer.loadComponentWithDependenciesFromModel(id);
  const componentMap = componentFromFS && componentFromFS.componentMap;
  if (componentFromFS && !componentMap) throw new (_generalError().default)('applyVersion: componentMap was not found');

  if (componentMap && componentMap.origin === _constants().COMPONENT_ORIGINS.AUTHORED && !id.scope) {
    componentWithDependencies.dependencies = [];
    componentWithDependencies.devDependencies = [];
  }

  const files = componentWithDependencies.component.files;
  files.forEach(file => {
    filesStatus[(0, _path2().pathNormalizeToLinux)(file.relative)] = _mergeVersion().FileStatus.updated;
  });

  if (mergeResults) {
    // update files according to the merge results
    const {
      filesStatus: modifiedStatus,
      modifiedFiles
    } = applyModifiedVersion(files, mergeResults, mergeStrategy, componentWithDependencies.component.originallySharedDir);
    filesStatus = _objectSpread(_objectSpread({}, filesStatus), modifiedStatus);
    componentWithDependencies.component.files = modifiedFiles;
  }

  const shouldDependenciesSaveAsComponents = await consumer.shouldDependenciesSavedAsComponents([id]);
  componentWithDependencies.component.dependenciesSavedAsComponents = shouldDependenciesSaveAsComponents[0].saveDependenciesAsComponents;
  return {
    applyVersionResult: {
      id,
      filesStatus
    },
    component: componentWithDependencies
  };
}
/**
 * relevant only when
 * 1) there is no conflict => add files from mergeResults: addFiles, overrideFiles and modifiedFiles.output.
 * 2) there is conflict and mergeStrategy is manual => add files from mergeResults: addFiles, overrideFiles and modifiedFiles.conflict.
 *
 * this function only updates the files content, it doesn't write the files
 */


function applyModifiedVersion(componentFiles, mergeResults, mergeStrategy, sharedDir) {
  let modifiedFiles = componentFiles.map(file => file.clone());
  const filesStatus = {};

  if (mergeResults.hasConflicts && mergeStrategy !== _mergeVersion().MergeOptions.manual) {
    return {
      filesStatus,
      modifiedFiles
    };
  }

  mergeResults.modifiedFiles.forEach(file => {
    const filePath = path().normalize(file.filePath);

    const pathWithSharedDir = p => sharedDir ? path().join(sharedDir, p) : p;

    const foundFile = modifiedFiles.find(componentFile => pathWithSharedDir(componentFile.relative) === filePath);
    if (!foundFile) throw new (_generalError().default)(`file ${filePath} not found`);

    if (file.conflict) {
      foundFile.contents = Buffer.from(file.conflict);
      filesStatus[file.filePath] = _mergeVersion().FileStatus.manual;
    } else if (file.output) {
      foundFile.contents = Buffer.from(file.output);
      filesStatus[file.filePath] = _mergeVersion().FileStatus.merged;
    } else if (file.isBinaryConflict) {
      // leave the file as is and notify the user later about it.
      foundFile.contents = file.fsFile.contents;
      filesStatus[file.filePath] = _mergeVersion().FileStatus.binaryConflict;
    } else {
      throw new (_generalError().default)(`file ${filePath} does not have output nor conflict`);
    }
  });
  mergeResults.addFiles.forEach(file => {
    modifiedFiles.push(file.fsFile);
    filesStatus[file.filePath] = _mergeVersion().FileStatus.added;
  });
  mergeResults.removeFiles.forEach(file => {
    const filePath = path().normalize(file.filePath);
    filesStatus[file.filePath] = _mergeVersion().FileStatus.removed;
    modifiedFiles = modifiedFiles.filter(f => f.relative !== filePath);
  });
  mergeResults.remainDeletedFiles.forEach(file => {
    const filePath = path().normalize(file.filePath);
    modifiedFiles = modifiedFiles.filter(f => f.relative !== filePath);
    filesStatus[file.filePath] = _mergeVersion().FileStatus.remainDeleted;
  });
  mergeResults.overrideFiles.forEach(file => {
    const filePath = path().normalize(file.filePath);
    const foundFile = modifiedFiles.find(componentFile => componentFile.relative === filePath);
    if (!foundFile) throw new (_generalError().default)(`file ${filePath} not found`);
    foundFile.contents = file.fsFile.contents;
    filesStatus[file.filePath] = _mergeVersion().FileStatus.overridden;
  });
  mergeResults.updatedFiles.forEach(file => {
    const filePath = path().normalize(file.filePath);
    const foundFile = modifiedFiles.find(componentFile => componentFile.relative === filePath);
    if (!foundFile) throw new (_generalError().default)(`file ${filePath} not found`);
    foundFile.contents = file.content;
    filesStatus[file.filePath] = _mergeVersion().FileStatus.updated;
  });
  return {
    filesStatus,
    modifiedFiles
  };
}
/**
 * when files exist on the filesystem but not on the checked out versions, they need to be deleted.
 * this function only mark them as such. later `deleteFilesIfNeeded()` will delete them
 */


function markFilesToBeRemovedIfNeeded(succeededComponents, componentsResults) {
  const succeededComponentsByBitId = succeededComponents.reduce((accum, next) => {
    const bitId = next.id.toString();
    if (!accum[bitId]) accum[bitId] = next;
    return accum;
  }, {});
  componentsResults.forEach(componentResult => {
    var _succeededComponent$c;

    const existingFilePathsFromModel = componentResult.applyVersionResult.filesStatus;
    const bitId = componentResult.applyVersionResult.id.toString();
    const succeededComponent = succeededComponentsByBitId[bitId];
    const filePathsFromFS = ((_succeededComponent$c = succeededComponent.componentFromFS) === null || _succeededComponent$c === void 0 ? void 0 : _succeededComponent$c.files) || [];
    filePathsFromFS.forEach(file => {
      const filename = (0, _path2().pathNormalizeToLinux)(file.relative);

      if (!existingFilePathsFromModel[filename]) {
        // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
        existingFilePathsFromModel[filename] = _mergeVersion().FileStatus.removed;
      }
    });
  });
}
/**
 * it's needed in case the checked out version removed files that exist on the current version.
 * without this function, these files would be left on the filesystem.
 */


async function deleteFilesIfNeeded(componentsResults, consumer) {
  const pathsToRemoveIncludeNull = componentsResults.map(compResult => {
    return Object.keys(compResult.applyVersionResult.filesStatus).map(filePath => {
      if (compResult.applyVersionResult.filesStatus[filePath] === _mergeVersion().FileStatus.removed) {
        var _compResult$component, _compResult$component2;

        if (!((_compResult$component = compResult.component) !== null && _compResult$component !== void 0 && _compResult$component.component.writtenPath)) return null;
        return path().join((_compResult$component2 = compResult.component) === null || _compResult$component2 === void 0 ? void 0 : _compResult$component2.component.writtenPath, filePath);
      }

      return null;
    });
  });
  const pathsToRemove = (0, _lodash().compact)(pathsToRemoveIncludeNull.flat());
  const dataToPersist = new (_dataToPersist().default)();
  dataToPersist.removeManyPaths(pathsToRemove.map(p => new (_removePath().default)(p, true)));
  dataToPersist.addBasePath(consumer.getPath());
  await dataToPersist.persistAllToFS();
}